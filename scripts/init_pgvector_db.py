"""
åˆå§‹åŒ– PGVector å‘é‡æ•°æ®åº“
åˆ›å»ºPGVectoræ‰©å±•å¹¶æµ‹è¯•å‘é‡å­˜å‚¨åŠŸèƒ½
"""
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from sqlalchemy import text
from storage.database.db import get_engine
from tools.vector_store import get_embeddings, get_vector_store, check_vector_store_setup
from tools.document_loader import load_document
from langchain_core.documents import Document


def create_pgvector_extension():
    """åˆ›å»ºPGVectoræ‰©å±•"""
    print("=" * 50)
    print("æ­¥éª¤ 1: åˆ›å»º PGVector æ‰©å±•")
    print("=" * 50)

    engine = get_engine()

    try:
        with engine.connect() as conn:
            # æ£€æŸ¥æ‰©å±•æ˜¯å¦å·²å­˜åœ¨
            result = conn.execute(text(
                "SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname = 'vector')"
            ))
            exists = result.scalar()

            if exists:
                print("âœ“ PGVector æ‰©å±•å·²å­˜åœ¨")
            else:
                # åˆ›å»ºæ‰©å±•
                conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
                conn.commit()
                print("âœ“ PGVector æ‰©å±•åˆ›å»ºæˆåŠŸ")

    except Exception as e:
        print(f"âœ— åˆ›å»º PGVector æ‰©å±•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    return True


def test_embedding_api():
    """æµ‹è¯•Embedding API"""
    print("\n" + "=" * 50)
    print("æ­¥éª¤ 2: æµ‹è¯• Embedding API")
    print("=" * 50)

    try:
        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨æ¨¡æ‹ŸEmbedding
        use_mock = input("ä½¿ç”¨æ¨¡æ‹ŸEmbeddingè¿›è¡Œæµ‹è¯•ï¼Ÿ(y/n): ").strip().lower()

        if use_mock == 'y':
            print("\nä½¿ç”¨æ¨¡æ‹ŸEmbeddingï¼ˆä»…ç”¨äºåŠŸèƒ½æµ‹è¯•ï¼‰...")
            from tools.mock_embedding import get_mock_embeddings
            embeddings = get_mock_embeddings()
            print(f"âœ“ æ¨¡æ‹ŸEmbeddings å®ä¾‹åˆ›å»ºæˆåŠŸ")
            print(f"  æ¨¡å‹: mock-embedding")
        else:
            print("\nå°è¯•ä½¿ç”¨è±†åŒ…Embedding API...")
            embeddings = get_embeddings()
            print(f"âœ“ Embeddings å®ä¾‹åˆ›å»ºæˆåŠŸ")
            print(f"  æ¨¡å‹: doubao-embedding-large-text-250515")

        # æµ‹è¯•åµŒå…¥å•ä¸ªæ–‡æœ¬
        test_text = "å»ºè´¦çš„åŸºæœ¬åŸåˆ™"
        print(f"\næµ‹è¯•æ–‡æœ¬: {test_text}")

        vector = embeddings.embed_query(test_text)
        print(f"âœ“ åµŒå…¥æˆåŠŸ")
        print(f"  å‘é‡ç»´åº¦: {len(vector)}")
        print(f"  å‰5ä¸ªå€¼: {vector[:5]}")

        # æµ‹è¯•æ‰¹é‡åµŒå…¥
        test_texts = ["ä»€ä¹ˆæ˜¯å»ºè´¦", "å¦‚ä½•è¿›è¡Œå‡­è¯å®¡æ ¸", "æ—¥è®°è´¦çš„åˆ†ç±»"]
        print(f"\næµ‹è¯•æ‰¹é‡åµŒå…¥ ({len(test_texts)} ä¸ªæ–‡æœ¬)...")

        vectors = embeddings.embed_documents(test_texts)
        print(f"âœ“ æ‰¹é‡åµŒå…¥æˆåŠŸ")
        print(f"  è¿”å›å‘é‡æ•°é‡: {len(vectors)}")
        print(f"  æ¯ä¸ªå‘é‡ç»´åº¦: {len(vectors[0])}")

        return True

    except Exception as e:
        print(f"âœ— æµ‹è¯• Embedding API å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_vector_store():
    """æµ‹è¯•å‘é‡å­˜å‚¨åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("æ­¥éª¤ 3: æµ‹è¯•å‘é‡å­˜å‚¨åŠŸèƒ½")
    print("=" * 50)

    try:
        # è¯¢é—®ä½¿ç”¨å“ªç§Embedding
        use_mock = input("\nä½¿ç”¨æ¨¡æ‹ŸEmbeddingæµ‹è¯•å‘é‡å­˜å‚¨ï¼Ÿ(y/n): ").strip().lower()

        if use_mock == 'y':
            print("ä½¿ç”¨æ¨¡æ‹ŸEmbedding...")
            from tools.mock_embedding import get_mock_embeddings
            embeddings = get_mock_embeddings()
        else:
            print("ä½¿ç”¨çœŸå®Embedding...")
            embeddings = get_embeddings()

        # è·å–å‘é‡å­˜å‚¨å®ä¾‹
        vector_store = get_vector_store(
            collection_name="test_collection",
            embeddings=embeddings
        )
        print("âœ“ å‘é‡å­˜å‚¨å®ä¾‹åˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        test_docs = [
            Document(
                page_content="å»ºè´¦çš„åŸºæœ¬åŸåˆ™åŒ…æ‹¬ï¼šçœŸå®æ€§åŸåˆ™ã€å®Œæ•´æ€§åŸåˆ™ã€åŠæ—¶æ€§åŸåˆ™ã€ä¸€è‡´æ€§åŸåˆ™å’Œé‡è¦æ€§åŸåˆ™ã€‚",
                metadata={"source": "å»ºè´¦è§„åˆ™.md", "category": "åŸºç¡€è§„åˆ™"}
            ),
            Document(
                page_content="å‡­è¯å®¡æ ¸çš„ä¸»è¦æµç¨‹åŒ…æ‹¬ï¼šå®¡æ ¸åŸå§‹å‡­è¯çš„çœŸå®æ€§å’Œåˆæ³•æ€§ã€å®¡æ ¸è®°è´¦å‡­è¯çš„æ­£ç¡®æ€§å’Œå®Œæ•´æ€§ã€å®¡æ ¸å‡­è¯çš„åˆè§„æ€§å’Œåˆç†æ€§ã€‚",
                metadata={"source": "å®¡æ ¸æµç¨‹.md", "category": "æµç¨‹è§„èŒƒ"}
            ),
            Document(
                page_content="æ—¥è®°è´¦åˆ†ä¸ºç°é‡‘æ—¥è®°è´¦ã€é“¶è¡Œå­˜æ¬¾æ—¥è®°è´¦å’Œå…¶ä»–è´§å¸èµ„é‡‘æ—¥è®°è´¦ã€‚ç°é‡‘æ—¥è®°è´¦ç”¨äºè®°å½•ç°é‡‘çš„æ”¶ä»˜ä¸šåŠ¡ã€‚",
                metadata={"source": "æ—¥è®°è´¦è§„èŒƒ.md", "category": "è´¦ç°¿ç®¡ç†"}
            )
        ]

        print(f"\nå‡†å¤‡æ·»åŠ  {len(test_docs)} ä¸ªæµ‹è¯•æ–‡æ¡£...")
        for i, doc in enumerate(test_docs, 1):
            print(f"  {i}. {doc.metadata['source']}")

        # æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨
        vector_store.add_documents(test_docs)
        print("âœ“ æ–‡æ¡£æ·»åŠ æˆåŠŸ")

        # æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢
        query = "å»ºè´¦çš„åŸºæœ¬åŸåˆ™æœ‰å“ªäº›"
        print(f"\næµ‹è¯•æœç´¢: {query}")

        results = vector_store.similarity_search(query, k=3)
        print(f"âœ“ æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(results)} ä¸ªç»“æœ\n")

        for i, doc in enumerate(results, 1):
            print(f"  ç»“æœ {i}:")
            print(f"    æ¥æº: {doc.metadata.get('source', 'unknown')}")
            print(f"    å†…å®¹: {doc.page_content[:100]}...")
            print()

        # æµ‹è¯•å¸¦åˆ†æ•°çš„æœç´¢
        print("æµ‹è¯•å¸¦åˆ†æ•°çš„æœç´¢...")
        results_with_scores = vector_store.similarity_search_with_score(query, k=3)
        print(f"âœ“ æœç´¢æˆåŠŸ\n")

        for i, (doc, score) in enumerate(results_with_scores, 1):
            print(f"  ç»“æœ {i}:")
            print(f"    ç›¸ä¼¼åº¦: {score:.4f}")
            print(f"    æ¥æº: {doc.metadata.get('source', 'unknown')}")
            print(f"    å†…å®¹: {doc.page_content[:100]}...")
            print()

        # æ¸…ç†æµ‹è¯•æ•°æ®
        print("æ¸…ç†æµ‹è¯•æ•°æ®...")
        vector_store.delete_collection()
        print("âœ“ æµ‹è¯•æ•°æ®å·²æ¸…ç†")

        return True

    except Exception as e:
        print(f"âœ— æµ‹è¯•å‘é‡å­˜å‚¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_with_real_document():
    """ä½¿ç”¨çœŸå®æ–‡æ¡£æµ‹è¯•"""
    print("\n" + "=" * 50)
    print("æ­¥éª¤ 4: ä½¿ç”¨çœŸå®æ–‡æ¡£æµ‹è¯•")
    print("=" * 50)

    # æŸ¥æ‰¾assetsç›®å½•ä¸‹çš„æµ‹è¯•æ–‡æ¡£
    workspace_path = os.getenv("COZE_WORKSPACE_PATH", "/workspace/projects")
    test_docs_dir = os.path.join(workspace_path, "assets")

    # æŸ¥æ‰¾Markdownæ–‡æ¡£
    markdown_files = []
    for root, dirs, files in os.walk(test_docs_dir):
        for file in files:
            if file.endswith('.md'):
                markdown_files.append(os.path.join(root, file))

    if not markdown_files:
        print("âœ— æœªæ‰¾åˆ°æµ‹è¯•æ–‡æ¡£")
        print("  è¯·åœ¨ assets/ ç›®å½•ä¸‹æ”¾ç½® .md æ–‡æ¡£")
        return False

    print(f"æ‰¾åˆ° {len(markdown_files)} ä¸ªæ–‡æ¡£:")
    for file in markdown_files:
        print(f"  - {os.path.relpath(file, test_docs_dir)}")

    # é€‰æ‹©ç¬¬ä¸€ä¸ªæ–‡æ¡£è¿›è¡Œæµ‹è¯•
    test_file = markdown_files[0]
    print(f"\nä½¿ç”¨æ–‡æ¡£: {os.path.basename(test_file)}")

    try:
        # åŠ è½½æ–‡æ¡£
        docs = load_document(file_path=test_file)
        print(f"âœ“ æ–‡æ¡£åŠ è½½æˆåŠŸï¼Œå…± {len(docs)} ä¸ªchunk")

        # æ·»åŠ åˆ°çŸ¥è¯†åº“
        vector_store = get_vector_store(collection_name="knowledge_base")
        print("æ­£åœ¨æ·»åŠ åˆ°çŸ¥è¯†åº“...")

        # æ‰¹é‡æ·»åŠ ï¼ˆæ¯æ¬¡10ä¸ªï¼‰
        batch_size = 10
        for i in range(0, len(docs), batch_size):
            batch = docs[i:i+batch_size]
            vector_store.add_documents(batch)
            print(f"  è¿›åº¦: {min(i+batch_size, len(docs))}/{len(docs)}")

        print("âœ“ æ–‡æ¡£å·²æ·»åŠ åˆ°çŸ¥è¯†åº“")

        # æµ‹è¯•æ£€ç´¢
        print("\næµ‹è¯•æ£€ç´¢åŠŸèƒ½...")
        test_queries = [
            "å»ºè´¦çš„åŸºæœ¬åŸåˆ™",
            "å¦‚ä½•è¿›è¡Œå‡­è¯å®¡æ ¸",
            "æ—¥è®°è´¦çš„åˆ†ç±»"
        ]

        for query in test_queries:
            print(f"\næŸ¥è¯¢: {query}")
            results = vector_store.similarity_search(query, k=2)

            for i, doc in enumerate(results, 1):
                print(f"  {i}. {doc.page_content[:80]}...")

        return True

    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\n")
    print("=" * 60)
    print("PGVector å‘é‡æ•°æ®åº“åˆå§‹åŒ–")
    print("=" * 60)

    # æ­¥éª¤ 1: æ˜¾ç¤ºé…ç½®çŠ¶æ€
    print("\nğŸ“Š å‘é‡å­˜å‚¨é…ç½®çŠ¶æ€:")
    print("=" * 60)
    print(check_vector_store_setup())

    # æ­¥éª¤ 2: åˆ›å»ºPGVectoræ‰©å±•
    if not create_pgvector_extension():
        print("\nâœ— åˆå§‹åŒ–å¤±è´¥ï¼šæ— æ³•åˆ›å»º PGVector æ‰©å±•")
        return False

    # æ­¥éª¤ 3: æµ‹è¯•Embedding API
    if not test_embedding_api():
        print("\nâš ï¸ Embedding API æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å‘é‡å­˜å‚¨æµ‹è¯•")
        print("æç¤º: å¯ä»¥ä½¿ç”¨æ¨¡æ‹ŸEmbeddingè¿›è¡ŒåŠŸèƒ½æµ‹è¯•")
        return False

    # æ­¥éª¤ 4: æµ‹è¯•å‘é‡å­˜å‚¨
    if not test_vector_store():
        print("\nâœ— åˆå§‹åŒ–å¤±è´¥ï¼šæ— æ³•æµ‹è¯•å‘é‡å­˜å‚¨")
        return False

    # æ­¥éª¤ 5: ä½¿ç”¨çœŸå®æ–‡æ¡£æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    test_real = input("\næ˜¯å¦ä½¿ç”¨çœŸå®æ–‡æ¡£æµ‹è¯•ï¼Ÿ(y/n): ").strip().lower()
    if test_real == 'y':
        test_with_real_document()

    # å®Œæˆ
    print("\n" + "=" * 60)
    print("âœ“ åˆå§‹åŒ–å®Œæˆï¼")
    print("=" * 60)
    print("\nä¸‹ä¸€æ­¥:")
    print("  1. è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯åŠŸèƒ½: python tests/test_rag_strategy.py")
    print("  2. å¯åŠ¨WebæœåŠ¡: python src/web/app.py")
    print("  3. è®¿é—® http://localhost:5000/rag-config æµ‹è¯•RAGé…ç½®")
    print("=" * 60)

    return True


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
