"""
RAG æ£€ç´¢å·¥å…·
æ•´åˆå‘é‡æ£€ç´¢å’Œ Rerank é‡æ’
"""
import json
from typing import Optional, List
from langchain.tools import tool
from langchain_core.documents import Document

# å¯¼å…¥ç›¸å…³å·¥å…·
from tools.vector_store import get_vector_store
from tools.reranker_tool import _init_reranker, _reranker_model


@tool
def rag_retrieve_with_rerank(
    query: str,
    collection_name: Optional[str] = "knowledge_base",
    initial_k: Optional[int] = 20,
    top_n: Optional[int] = 5,
    use_rerank: Optional[bool] = True,
    rerank_model: Optional[str] = "BAAI/bge-reranker-large"
) -> str:
    """
    RAG æ£€ç´¢ï¼ˆå‘é‡æ£€ç´¢ + Rerank é‡æ’ï¼‰

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        collection_name: å‘é‡é›†åˆåç§°
        initial_k: åˆå§‹æ£€ç´¢æ–‡æ¡£æ•°ï¼ˆç”¨äº rerankï¼Œé»˜è®¤ 20ï¼‰
        top_n: æœ€ç»ˆè¿”å›çš„æ–‡æ¡£æ•°ï¼ˆrerank åï¼Œé»˜è®¤ 5ï¼‰
        use_rerank: æ˜¯å¦ä½¿ç”¨ rerankï¼ˆé»˜è®¤ Trueï¼‰
        rerank_model: reranker æ¨¡å‹åç§°
            - "BAAI/bge-reranker-large": å¤§æ¨¡å‹ï¼ˆé»˜è®¤ï¼‰
            - "BAAI/bge-reranker-base": åŸºç¡€æ¨¡å‹ï¼ˆæ›´å¿«ï¼‰

    Returns:
        æ£€ç´¢ç»“æœï¼ˆå¸¦ç›¸ä¼¼åº¦åˆ†æ•°å’Œ rerank åˆ†æ•°ï¼‰

    Raises:
        ValueError: å¦‚æœæŸ¥è¯¢ä¸ºç©º
        RuntimeError: å¦‚æœæ£€ç´¢å¤±è´¥
    """
    if not query or not query.strip():
        raise ValueError("æŸ¥è¯¢ä¸èƒ½ä¸ºç©º")

    try:
        # ç¬¬ä¸€æ­¥ï¼šå‘é‡æ£€ç´¢
        vector_store = get_vector_store(collection_name=collection_name)

        # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
        vector_results = vector_store.similarity_search_with_score(
            query=query,
            k=initial_k
        )

        if not vector_results:
            return f"ğŸ” RAG æ£€ç´¢ç»“æœ\n\næœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£\n"

        # ç¬¬äºŒæ­¥ï¼šRerank é‡æ’ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_rerank:
            # åˆå§‹åŒ– reranker
            reranker = _init_reranker(rerank_model)

            # å‡†å¤‡ rerank è¾“å…¥
            rerank_inputs = []
            for doc, score in vector_results:
                rerank_inputs.append([query, doc.page_content])

            # æ‰§è¡Œ rerank
            rerank_scores = reranker.predict(rerank_inputs)

            # ç»„åˆç»“æœ
            ranked_results = []
            for (doc, vec_score), rerank_score in zip(vector_results, rerank_scores):
                ranked_results.append({
                    "document": doc,
                    "vector_score": float(vec_score),
                    "rerank_score": float(rerank_score)
                })

            # æŒ‰ rerank åˆ†æ•°é™åºæ’åº
            ranked_results.sort(key=lambda x: x["rerank_score"], reverse=True)

            # è¿”å› top-n ç»“æœ
            top_results = ranked_results[:top_n]
        else:
            # ä¸ä½¿ç”¨ rerankï¼Œç›´æ¥è¿”å›å‘é‡æ£€ç´¢ç»“æœ
            top_results = []
            for doc, score in vector_results[:top_n]:
                top_results.append({
                    "document": doc,
                    "vector_score": float(score),
                    "rerank_score": None
                })

        # æ ¼å¼åŒ–è¾“å‡º
        result = f"ğŸ” RAG æ£€ç´¢ç»“æœ\n"
        result += f"æŸ¥è¯¢: {query}\n"
        result += f"ä½¿ç”¨ Rerank: {'æ˜¯' if use_rerank else 'å¦'}\n"
        if use_rerank:
            result += f"Rerank æ¨¡å‹: {rerank_model}\n"
        result += f"åˆå§‹æ£€ç´¢: {initial_k} æ–‡æ¡£\n"
        result += f"è¿”å›ç»“æœ: {len(top_results)} æ–‡æ¡£\n"
        result += "=" * 50 + "\n\n"

        for i, item in enumerate(top_results, 1):
            doc = item["document"]
            result += f"ã€ç»“æœ {i}ã€‘\n"
            result += f"å‘é‡ç›¸ä¼¼åº¦: {item['vector_score']:.4f}\n"
            if item["rerank_score"] is not None:
                result += f"Rerank åˆ†æ•°: {item['rerank_score']:.4f}\n"
            result += f"å†…å®¹: {doc.page_content[:400]}...\n"
            if doc.metadata:
                result += f"æ¥æº: {doc.metadata.get('source', 'æœªçŸ¥')}\n"
                result += f"å…ƒæ•°æ®: {json.dumps(doc.metadata, ensure_ascii=False)}\n"
            result += "\n"

        return result

    except Exception as e:
        raise RuntimeError(f"RAG æ£€ç´¢å¤±è´¥: {str(e)}")


@tool
def hybrid_search(
    query: str,
    collection_name: Optional[str] = "knowledge_base",
    k: Optional[int] = 5
) -> str:
    """
    æ··åˆæœç´¢ï¼ˆåŒæ—¶è¿”å›å‘é‡æ£€ç´¢å’Œ Rerank ç»“æœå¯¹æ¯”ï¼‰

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        collection_name: å‘é‡é›†åˆåç§°
        k: è¿”å›çš„æ–‡æ¡£æ•°

    Returns:
        æ··åˆæœç´¢ç»“æœï¼ˆå¯¹æ¯”å‘é‡æ£€ç´¢å’Œ Rerank ç»“æœï¼‰
    """
    if not query or not query.strip():
        raise ValueError("æŸ¥è¯¢ä¸èƒ½ä¸ºç©º")

    try:
        # å‘é‡æ£€ç´¢
        vector_result = rag_retrieve_with_rerank(
            query=query,
            collection_name=collection_name,
            initial_k=k,
            top_n=k,
            use_rerank=False
        )

        # Rerank æ£€ç´¢
        rerank_result = rag_retrieve_with_rerank(
            query=query,
            collection_name=collection_name,
            initial_k=k * 2,  # Rerank éœ€è¦æ›´å¤šå€™é€‰
            top_n=k,
            use_rerank=True
        )

        # å¯¹æ¯”ç»“æœ
        result = f"ğŸ”„ æ··åˆæœç´¢å¯¹æ¯”\n"
        result += f"æŸ¥è¯¢: {query}\n"
        result += "=" * 50 + "\n\n"
        result += "ã€å‘é‡æ£€ç´¢ç»“æœã€‘\n"
        result += vector_result + "\n\n"
        result += "ã€Rerank æ£€ç´¢ç»“æœã€‘\n"
        result += rerank_result

        return result

    except Exception as e:
        raise RuntimeError(f"æ··åˆæœç´¢å¤±è´¥: {str(e)}")


@tool
def format_docs_for_rag(
    docs: str,
    max_length: Optional[int] = 2000
) -> str:
    """
    æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£ç”¨äº RAG ç”Ÿæˆ

    Args:
        docs: æ–‡æ¡£åˆ—è¡¨ï¼ˆJSON å­—ç¬¦ä¸²æ ¼å¼ï¼‰
            æ ¼å¼ç¤ºä¾‹:
            [
                {"content": "æ–‡æ¡£1å†…å®¹", "metadata": {"source": "doc1"}},
                {"content": "æ–‡æ¡£2å†…å®¹", "metadata": {"source": "doc2"}}
            ]
        max_length: æ€»å†…å®¹æœ€å¤§é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰

    Returns:
        æ ¼å¼åŒ–çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆç”¨äº LLM ä¸Šä¸‹æ–‡ï¼‰
    """
    try:
        # è§£ææ–‡æ¡£
        doc_list = json.loads(docs)

        # æ„å»ºæ ¼å¼åŒ–å†…å®¹
        formatted = "ä»¥ä¸‹æ˜¯ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹ï¼š\n\n"

        total_length = 0
        for i, doc in enumerate(doc_list, 1):
            content = doc.get('content', '')
            metadata = doc.get('metadata', {})
            source = metadata.get('source', f'æ–‡æ¡£ {i}')

            formatted_content = f"[æ¥æº: {source}]\n{content}\n\n"
            formatted_content_length = len(formatted_content)

            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºæœ€å¤§é•¿åº¦
            if max_length and total_length + formatted_content_length > max_length:
                formatted += f"... (å·²çœç•¥éƒ¨åˆ†å†…å®¹ä»¥ä¿æŒä¸Šä¸‹æ–‡åœ¨ {max_length} å­—ç¬¦ä»¥å†…)\n"
                break

            formatted += formatted_content
            total_length += formatted_content_length

        return formatted

    except json.JSONDecodeError:
        raise ValueError("docs åº”è¯¥æ˜¯æœ‰æ•ˆçš„ JSON æ•°ç»„æ ¼å¼")
    except Exception as e:
        raise RuntimeError(f"æ ¼å¼åŒ–æ–‡æ¡£å¤±è´¥: {str(e)}")
