#!/usr/bin/env python3
"""
RAGåŠŸèƒ½é›†æˆæµ‹è¯•è„šæœ¬
æµ‹è¯•æ–‡æ¡£åŠ è½½ã€åˆ†å‰²ã€å‘é‡åŒ–ã€æ£€ç´¢å’Œé—®ç­”å®Œæ•´æµç¨‹
"""

import os
import sys
import asyncio
import json
from pathlib import Path

# æ·»åŠ srcåˆ°è·¯å¾„
workspace_path = os.getenv("COZE_WORKSPACE_PATH", "/workspace/projects")
src_path = os.path.join(workspace_path, "src")
if src_path not in sys.path:
    sys.path.insert(0, src_path)

# å¯¼å…¥RAGå·¥å…·ï¼ˆä½¿ç”¨åŠ¨æ€å¯¼å…¥ï¼‰
try:
    from tools.document_loader import document_loader_tool
    from tools.text_splitter import text_splitter_tool
    from tools.vector_store import vector_store_tool
    from tools.reranker_tool import reranker_tool
    from tools.rag_retriever import rag_retrieve_with_rerank
except ImportError as e:
    print(f"å¯¼å…¥å·¥å…·å¤±è´¥: {e}")
    print("å°†ä½¿ç”¨åˆ›å»ºå‡½æ•°æ–¹å¼å¯¼å…¥å·¥å…·...")
    from tools.document_loader import create_document_loader_tool
    from tools.text_splitter import create_text_splitter_tool
    from tools.vector_store import create_vector_store_tool
    from tools.reranker_tool import create_reranker_tool

    document_loader_tool = create_document_loader_tool()
    text_splitter_tool = create_text_splitter_tool()
    vector_store_tool = create_vector_store_tool()
    reranker_tool = create_reranker_tool()


def test_document_loader():
    """æµ‹è¯•æ–‡æ¡£åŠ è½½åŠŸèƒ½"""
    print("\n" + "="*50)
    print("æµ‹è¯•1: æ–‡æ¡£åŠ è½½åŠŸèƒ½")
    print("="*50)

    try:
        # ä½¿ç”¨å·²å¯¼å…¥çš„å·¥å…·
        loader_tool = document_loader_tool

        # æµ‹è¯•åŠ è½½Markdownæ–‡æ¡£ï¼ˆåˆ›å»ºæµ‹è¯•æ–‡æ¡£ï¼‰
        test_md_content = """# å»ºè´¦è§„åˆ™è¯´æ˜

## 1. åŸºæœ¬åŸåˆ™
å»ºè´¦æ˜¯ä¼ä¸šè´¢åŠ¡ç®¡ç†çš„åŸºç¡€å·¥ä½œï¼Œéœ€è¦éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
- çœŸå®æ€§åŸåˆ™ï¼šç¡®ä¿æ‰€æœ‰æ•°æ®çœŸå®å‡†ç¡®
- å®Œæ•´æ€§åŸåˆ™ï¼šç¡®ä¿è´¦ç›®å®Œæ•´æ— é—æ¼
- åŠæ—¶æ€§åŸåˆ™ï¼šåŠæ—¶è®°å½•å’Œæ›´æ–°è´¦ç›®

## 2. å»ºè´¦æµç¨‹
1. æ”¶é›†åˆå§‹å‡­è¯
2. å¼€è®¾ä¼šè®¡ç§‘ç›®
3. å½•å…¥æœŸåˆä½™é¢
4. è¯•ç®—å¹³è¡¡
5. å»ºç«‹è´¦ç°¿ä½“ç³»

## 3. æ³¨æ„äº‹é¡¹
åœ¨å»ºè´¦è¿‡ç¨‹ä¸­ï¼Œéœ€è¦ç‰¹åˆ«æ³¨æ„ï¼š
- æ ¸å¯¹æœŸåˆä½™é¢çš„å‡†ç¡®æ€§
- é€‰æ‹©åˆé€‚çš„ä¼šè®¡æ”¿ç­–
- ç¡®ä¿ç§‘ç›®è®¾ç½®çš„åˆç†æ€§
"""
        test_md_path = "/tmp/test_document.md"
        with open(test_md_path, "w", encoding="utf-8") as f:
            f.write(test_md_content)

        # è°ƒç”¨å·¥å…·åŠ è½½æ–‡æ¡£
        result = loader_tool.invoke({"file_path": test_md_path})
        print(f"âœ“ æ–‡æ¡£åŠ è½½æˆåŠŸ")
        print(f"  å†…å®¹é•¿åº¦: {len(result)} å­—ç¬¦")
        print(f"  å†…å®¹é¢„è§ˆ: {result[:100]}...")

        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.remove(test_md_path)
        return True

    except Exception as e:
        print(f"âœ— æ–‡æ¡£åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_text_splitter():
    """æµ‹è¯•æ–‡æœ¬åˆ†å‰²åŠŸèƒ½"""
    print("\n" + "="*50)
    print("æµ‹è¯•2: æ–‡æœ¬åˆ†å‰²åŠŸèƒ½")
    print("="*50)

    try:
        # ä½¿ç”¨å·²å¯¼å…¥çš„å·¥å…·
        splitter_tool = text_splitter_tool

        # æµ‹è¯•æ–‡æœ¬
        test_text = """
è¿™æ˜¯ç¬¬ä¸€æ®µæ–‡å­—ï¼Œä»‹ç»å»ºè´¦çš„åŸºæœ¬æ¦‚å¿µã€‚å»ºè´¦æ˜¯æŒ‡æ ¹æ®ä¼šè®¡å‡†åˆ™å’Œä¼ä¸šå®é™…æƒ…å†µï¼Œå»ºç«‹ä¼šè®¡è´¦ç°¿ä½“ç³»çš„è¿‡ç¨‹ã€‚

è¿™æ˜¯ç¬¬äºŒæ®µæ–‡å­—ï¼Œè¯´æ˜å»ºè´¦çš„é‡è¦æ€§ã€‚ä¸€ä¸ªå®Œå–„çš„ä¼šè®¡è´¦ç°¿ä½“ç³»æ˜¯ä¼ä¸šè´¢åŠ¡ç®¡ç†çš„åŸºç¡€ï¼Œèƒ½å¤Ÿä¸ºä¼ä¸šå†³ç­–æä¾›å‡†ç¡®çš„æ•°æ®æ”¯æŒã€‚

è¿™æ˜¯ç¬¬ä¸‰æ®µæ–‡å­—ï¼Œè®²è§£å»ºè´¦çš„æ­¥éª¤ã€‚å»ºè´¦é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼šæ”¶é›†åŸå§‹å‡­è¯ã€è®¾ç½®ä¼šè®¡ç§‘ç›®ã€å½•å…¥æœŸåˆä½™é¢ã€è¯•ç®—å¹³è¡¡ç­‰ã€‚

è¿™æ˜¯ç¬¬å››æ®µæ–‡å­—ï¼Œå¼ºè°ƒå»ºè´¦çš„æ³¨æ„äº‹é¡¹ã€‚åœ¨å»ºè´¦è¿‡ç¨‹ä¸­ï¼Œéœ€è¦ç¡®ä¿ä¼šè®¡ç§‘ç›®çš„è®¾ç½®ç¬¦åˆä¼ä¸šå®é™…æƒ…å†µï¼ŒæœŸåˆä½™é¢çš„å½•å…¥å‡†ç¡®æ— è¯¯ã€‚
        """ * 3  # é‡å¤å¤šæ¬¡ä»¥æµ‹è¯•åˆ†å‰²

        # è°ƒç”¨å·¥å…·åˆ†å‰²æ–‡æœ¬
        result = splitter_tool.invoke({
            "text": test_text,
            "chunk_size": 200,
            "chunk_overlap": 50
        })
        chunks = json.loads(result)

        print(f"âœ“ æ–‡æœ¬åˆ†å‰²æˆåŠŸ")
        print(f"  åŸå§‹æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
        print(f"  åˆ†å‰²åå—æ•°: {len(chunks)}")
        print(f"  ç¬¬ä¸€å—é•¿åº¦: {len(chunks[0])} å­—ç¬¦")
        print(f"  ç¬¬ä¸€å—å†…å®¹: {chunks[0][:80]}...")

        return True

    except Exception as e:
        print(f"âœ— æ–‡æœ¬åˆ†å‰²æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_vector_store():
    """æµ‹è¯•å‘é‡å­˜å‚¨åŠŸèƒ½"""
    print("\n" + "="*50)
    print("æµ‹è¯•3: å‘é‡å­˜å‚¨åŠŸèƒ½")
    print("="*50)

    try:
        # ä½¿ç”¨å·²å¯¼å…¥çš„å·¥å…·
        vector_store_tool_instance = vector_store_tool

        # æµ‹è¯•æ–‡æ¡£å—
        test_docs = [
            {"text": "å»ºè´¦æ˜¯è´¢åŠ¡ç®¡ç†çš„åŸºç¡€å·¥ä½œ", "metadata": {"source": "test", "page": 1}},
            {"text": "ä¼šè®¡ç§‘ç›®è®¾ç½®éœ€è¦ç¬¦åˆä¼ä¸šå®é™…æƒ…å†µ", "metadata": {"source": "test", "page": 2}},
            {"text": "æœŸåˆä½™é¢çš„å½•å…¥å¿…é¡»å‡†ç¡®æ— è¯¯", "metadata": {"source": "test", "page": 3}},
        ]

        # è°ƒç”¨å·¥å…·æ·»åŠ æ–‡æ¡£
        result = vector_store_tool_instance.invoke({
            "action": "add",
            "collection_name": "test_collection",
            "documents": json.dumps(test_docs)
        })

        print(f"âœ“ å‘é‡å­˜å‚¨æˆåŠŸ")
        print(f"  {result}")

        return True

    except Exception as e:
        print(f"âœ— å‘é‡å­˜å‚¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_reranker():
    """æµ‹è¯•Reranké‡æ’åºåŠŸèƒ½"""
    print("\n" + "="*50)
    print("æµ‹è¯•4: Reranké‡æ’åºåŠŸèƒ½")
    print("="*50)

    try:
        # ä½¿ç”¨å·²å¯¼å…¥çš„å·¥å…·
        reranker_tool_instance = reranker_tool

        # æµ‹è¯•æŸ¥è¯¢å’Œæ–‡æ¡£
        test_query = "å¦‚ä½•è¿›è¡Œå»ºè´¦å·¥ä½œï¼Ÿ"

        test_documents = [
            {"text": "å»ºè´¦æ˜¯ä¼ä¸šè´¢åŠ¡ç®¡ç†çš„åŸºç¡€å·¥ä½œ", "id": "1"},
            {"text": "ä»Šå¤©çš„å¤©æ°”å¾ˆå¥½", "id": "2"},
            {"text": "å»ºè´¦åŒ…æ‹¬æ”¶é›†åŸå§‹å‡­è¯ã€è®¾ç½®ç§‘ç›®ã€å½•å…¥æœŸåˆä½™é¢ç­‰æ­¥éª¤", "id": "3"},
            {"text": "è‚¡ç¥¨å¸‚åœºåˆ†æ", "id": "4"},
            {"text": "åœ¨å»ºè´¦è¿‡ç¨‹ä¸­éœ€è¦ç¡®ä¿æ•°æ®çš„çœŸå®æ€§å’Œå®Œæ•´æ€§", "id": "5"},
        ]

        # è°ƒç”¨å·¥å…·è¿›è¡Œé‡æ’åº
        result = reranker_tool_instance.invoke({
            "query": test_query,
            "documents": json.dumps(test_documents),
            "top_k": 3
        })

        reranked_docs = json.loads(result)

        print(f"âœ“ Reranké‡æ’åºæˆåŠŸ")
        print(f"  æŸ¥è¯¢: {test_query}")
        print(f"  é‡æ’åºåTop {len(reranked_docs)}:")
        for i, doc in enumerate(reranked_docs, 1):
            print(f"    {i}. [{doc.get('relevance_score', 0):.3f}] {doc['text'][:60]}...")

        return True

    except Exception as e:
        print(f"âœ— Reranké‡æ’åºæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_rag_qa():
    """æµ‹è¯•RAGé—®ç­”åŠŸèƒ½"""
    print("\n" + "="*50)
    print("æµ‹è¯•5: RAGé—®ç­”åŠŸèƒ½")
    print("="*50)

    try:
        # ä½¿ç”¨å·²å¯¼å…¥çš„å·¥å…·
        rag_tool = rag_retrieve_with_rerank

        # æµ‹è¯•é—®é¢˜
        test_questions = [
            "å»ºè´¦çš„åŸºæœ¬åŸåˆ™æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å»ºè´¦çš„æµç¨‹åŒ…æ‹¬å“ªäº›æ­¥éª¤ï¼Ÿ",
        ]

        for i, question in enumerate(test_questions, 1):
            print(f"\n--- é—®é¢˜ {i}: {question} ---")

            # è°ƒç”¨RAGå·¥å…·
            result = rag_tool.invoke({
                "query": question,
                "collection_name": "knowledge_base",
                "top_n": 3,
                "use_rerank": True
            })

            print(f"  æ£€ç´¢ç»“æœé¢„è§ˆ: {result[:200]}...")

        print(f"\nâœ“ RAGé—®ç­”åŠŸèƒ½æµ‹è¯•å®Œæˆ")

        return True

    except Exception as e:
        print(f"âœ— RAGé—®ç­”æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("RAGåŠŸèƒ½é›†æˆæµ‹è¯•")
    print("="*60)

    results = {
        "æ–‡æ¡£åŠ è½½": test_document_loader(),
        "æ–‡æœ¬åˆ†å‰²": test_text_splitter(),
        "å‘é‡å­˜å‚¨": test_vector_store(),
        "Reranké‡æ’åº": test_reranker(),
        "RAGé—®ç­”": test_rag_qa(),
    }

    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)

    passed = sum(1 for v in results.values() if v)
    total = len(results)

    for test_name, result in results.items():
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"  {test_name}: {status}")

    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼RAGç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())
